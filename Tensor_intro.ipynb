{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNYpXdseSXflZz9sPrkBh+d",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/beotavalo/ML-DL-Applications/blob/main/Tensor_intro.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction to tensor, tensor libraries, and tensor calculation\n",
        "In this lab, we are going to use the two most popular frameworks used in Deep Learning [PyTorch](https://pytorch.org/) and [TensorFlow](https://www.tensorflow.org/)."
      ],
      "metadata": {
        "id": "30FiT-kiL7WO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import tensorflow as tf\n",
        "\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"TensorFlow version: {tf.__version__}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6_sKHf0OFOA5",
        "outputId": "da75f8cb-379c-434d-a86d-fe5130fe5190"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch version: 2.3.0+cu121\n",
            "TensorFlow version: 2.15.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a tensor with the both PyTorch\n",
        "w = torch.ones(2, 3, 2)\n",
        "x = torch.rand(2,3, 2) #Random tensor nxm\n",
        "\n",
        "# Create a tensor with the TensorFlow\n",
        "y = tf.ones((2, 3, 3))\n",
        "z = tf.random.uniform((2, 3, 3)) #Random tensor nxm\n",
        "\n",
        "# Add the tensors\n",
        "torch_sum = torch.add(w, x)\n",
        "tf_sum = tf.add(y, z)\n",
        "\n",
        "# Print the results\n",
        "print(\"PyTorch sum:\")\n",
        "print(torch_sum)\n",
        "print(\"\\nTensorFlow sum:\")\n",
        "print(tf_sum)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LXmtIYiwFMbU",
        "outputId": "d6885621-2be2-47bd-b3d8-5ef23f8c6718"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch sum:\n",
            "tensor([[[1.5067, 1.7450],\n",
            "         [1.7303, 1.9192],\n",
            "         [1.0893, 1.0359]],\n",
            "\n",
            "        [[1.2707, 1.2528],\n",
            "         [1.4814, 1.1896],\n",
            "         [1.8674, 1.5155]]])\n",
            "\n",
            "TensorFlow sum:\n",
            "tf.Tensor(\n",
            "[[[1.2626388 1.0979536 1.4551301]\n",
            "  [1.305712  1.2043009 1.4468613]\n",
            "  [1.4253085 1.4531769 1.7109005]]\n",
            "\n",
            " [[1.5692545 1.0063932 1.655444 ]\n",
            "  [1.5986255 1.3533288 1.8927387]\n",
            "  [1.3101932 1.438307  1.4142678]]], shape=(2, 3, 3), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The shape of a Tensor defines its number of dimensions and the size of each dimension. The rank of a Tensor provides the number of dimensions (n-dimensions) -- you can also think of this as the Tensor's order or degree.\n",
        "\n",
        "Reference in this [link](https://github.com/aamini/introtodeeplearning/blob/master/lab1/solutions/Part1_TensorFlow_Solution.ipynb)"
      ],
      "metadata": {
        "id": "LpICQXUSNqfD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Shape and Rank of tensor in PyTorch\n",
        "\n",
        "print(\"Shape of `w`:\", w.shape)\n",
        "print(\"Rank of `w`:\", w.ndim)\n",
        "print(\"Shape of `x`:\", x.shape)\n",
        "print(\"Rank of `x`:\", x.ndim)\n",
        "\n",
        "#Shape and Rank of tensor in tensorflow\n",
        "print(\"`y` is a {}-d Tensor\".format(tf.shape(y).numpy()))\n",
        "print(\"`z` is a {}-d Tensor\".format(tf.shape(z).numpy()))\n",
        "print(\"`y` is a {}-d Tensor\".format(tf.rank(y).numpy()))\n",
        "print(\"`z` is a {}-d Tensor\".format(tf.rank(z).numpy()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I-CN_nuDK1-i",
        "outputId": "9b4ad319-5fdd-42d7-f661-ab4effb42311"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of `w`: torch.Size([2, 3, 2])\n",
            "Rank of `w`: 3\n",
            "Shape of `x`: torch.Size([2, 3, 2])\n",
            "Rank of `x`: 3\n",
            "`y` is a [2 3 3]-d Tensor\n",
            "`z` is a [2 3 3]-d Tensor\n",
            "`y` is a 3-d Tensor\n",
            "`z` is a 3-d Tensor\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sport = tf.constant(\"Tennis\", tf.string)\n",
        "number = tf.constant(1.41421356237, tf.float64)\n",
        "\n",
        "print(\"`sport` is a {}-d Tensor\".format(tf.rank(sport).numpy()))\n",
        "print(\"`number` is a {}-d Tensor\".format(tf.rank(number).numpy()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XtPByj44KaRG",
        "outputId": "3bb77bf7-714d-496e-9335-cd0f90efc532"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "`sport` is a 0-d Tensor\n",
            "`number` is a 0-d Tensor\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "music_genre = tf.constant([\"Salsa\", \"Rock\", 'Blues'], tf.string)\n",
        "numbers = tf.constant([2.1356, 4.674, 0.782, -0.235], tf.float64)\n",
        "\n",
        "print(\"`music genre` is a {}-d Tensor with shape: {}\".format(tf.rank(music_genre).numpy(), tf.shape(music_genre)))\n",
        "print(\"`numbers` is a {}-d Tensor with shape: {}\".format(tf.rank(numbers).numpy(), tf.shape(numbers)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h9YhCsJiN7M0",
        "outputId": "e8eaba8a-6619-493a-87a5-b2ba846bd6ff"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "`music genre` is a 1-d Tensor with shape: [3]\n",
            "`numbers` is a 1-d Tensor with shape: [4]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To work with strings using PyTorch should Install a version of PyTorch that supports the string data type\n",
        "torch==1.13\n",
        "\n",
        "```!pip install torch==1.13```"
      ],
      "metadata": {
        "id": "RwjIiVknPbZd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "numbers = torch.tensor([2.1356, 4.674, 0.782, -0.235], dtype=torch.float64)\n",
        "\n",
        "print(\"`numbers` is a {}-d Tensor with shape: {}\".format(numbers.dim(), numbers.shape))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nc884P0sO3b2",
        "outputId": "72128551-e80b-4889-c74b-251a4a2bee36"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "`numbers` is a 1-d Tensor with shape: torch.Size([4])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Defining higher-order Tensors ###\n",
        "\n",
        "'''TODO: Define a 2-d Tensor'''\n",
        "matrix = tf.constant([[1.0, 2.0, 3.0, 4.0], [5.0, 6.0, 7.0, 8.0]]) # TODO\n",
        "# matrix = # TODO\n",
        "\n",
        "assert isinstance(matrix, tf.Tensor), \"matrix must be a tf Tensor object\"\n",
        "assert tf.rank(matrix).numpy() == 2\n",
        "\n",
        "'''TODO: Define a 4-d Tensor.'''\n",
        "# Use tf.zeros to initialize a 4-d Tensor of zeros with size 10 x 256 x 256 x 3.\n",
        "#   You can think of this as 10 images where each image is RGB 256 x 256.\n",
        "images = tf.zeros([10, 256, 256, 3]) # TODO\n",
        "# images = # TODO\n",
        "\n",
        "assert isinstance(images, tf.Tensor), \"matrix must be a tf Tensor object\"\n",
        "assert tf.rank(images).numpy() == 4, \"matrix must be of rank 4\"\n",
        "assert tf.shape(images).numpy().tolist() == [10, 256, 256, 3], \"matrix is incorrect shape\"\n",
        "\n"
      ],
      "metadata": {
        "id": "xmzBR8hPZt0o"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "row_vector = matrix[0]\n",
        "column_vector = matrix[:,3]\n",
        "scalar = matrix[0, 3]\n",
        "\n",
        "print(\"`row_vector`: {}\".format(row_vector.numpy()))\n",
        "print(\"`column_vector`: {}\".format(column_vector.numpy()))\n",
        "print(\"`scalar`: {}\".format(scalar.numpy()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZtNZTkpKaSfI",
        "outputId": "d8e115ef-3fb7-4c78-b1af-678e60014da4"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "`row_vector`: [1. 2. 3. 4.]\n",
            "`column_vector`: [4. 8.]\n",
            "`scalar`: 4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "images = torch.zeros((10, 256, 256, 3))\n"
      ],
      "metadata": {
        "id": "oeUaKgXMbKBB"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "matrix_torch = torch.tensor([[1.0, 2.0, 3.0, 4.0], [5.0, 6.0, 7.0, 8.0]])\n",
        "row_vector_torch = matrix_torch[0]\n",
        "column_vector_torch = matrix_torch[:,3]\n",
        "scalar_torch = matrix_torch[0, 3]\n",
        "\n",
        "print(\"`row_vector`: {}\".format(row_vector_torch.numpy()))\n",
        "print(\"`column_vector`: {}\".format(column_vector_torch.numpy()))\n",
        "print(\"`scalar`: {}\".format(scalar_torch.numpy()))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P8GirOrFa28D",
        "outputId": "dfed5260-2d2a-48f2-9931-52b6502e91e6"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "`row_vector`: [1. 2. 3. 4.]\n",
            "`column_vector`: [4. 8.]\n",
            "`scalar`: 4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Computation on Tensors**"
      ],
      "metadata": {
        "id": "mYzE1R6oOiGt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "s1 = tf.constant(1.0)\n",
        "s2 = tf.constant(2.0)\n",
        "\n",
        "#Add\n",
        "s3 = s1 + s2\n",
        "s3_op = tf.add(s1, s2)\n",
        "#Multiply\n",
        "s4 = s1 * s2\n",
        "#Subtract\n",
        "s5 = s1 - s2\n",
        "#Division\n",
        "s6 = s1 / s2\n",
        "\n",
        "print(\"`s3`: {}\".format(s3.numpy()))\n",
        "print(\"`s4`: {}\".format(s4.numpy()))\n",
        "print(\"`s5`: {}\".format(s5.numpy()))\n",
        "print(\"`s6`: {}\".format(s6.numpy()))\n",
        "print(\"`s3_op`: {}\".format(s3_op.numpy()))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6UoCWXtxOlBq",
        "outputId": "3df46f63-cf99-4b4a-866d-9005b0459ded"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "`s3`: 3.0\n",
            "`s4`: 2.0\n",
            "`s5`: -1.0\n",
            "`s6`: 0.5\n",
            "`s3_op`: 3.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "s1 = tf.constant([1.0, 2.5])\n",
        "s2 = tf.constant([2.0, 6.3])\n",
        "\n",
        "#Add\n",
        "s3 = s1 + s2\n",
        "s3_op = tf.add(s1, s2)\n",
        "#Multiply\n",
        "s4 = s1 * s2\n",
        "#Subtract\n",
        "s5 = s1 - s2\n",
        "#Division\n",
        "s6 = s1 / s2\n",
        "\n",
        "print(\"`s3`: {}\".format(s3.numpy()))\n",
        "print(\"`s4`: {}\".format(s4.numpy()))\n",
        "print(\"`s5`: {}\".format(s5.numpy()))\n",
        "print(\"`s6`: {}\".format(s6.numpy()))\n",
        "print(\"`s3_op`: {}\".format(s3_op.numpy()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LzifoyxAdJZZ",
        "outputId": "e59e0274-d4df-4e5b-be24-9d36b911e7aa"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "`s3`: [3.  8.8]\n",
            "`s4`: [ 2.   15.75]\n",
            "`s5`: [-1.        -3.8000002]\n",
            "`s6`: [0.5        0.39682537]\n",
            "`s3_op`: [3.  8.8]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "s1 = torch.tensor([1.0, 2.5])\n",
        "s2 = torch.tensor([2.0, 6.3])\n",
        "#Add\n",
        "s3 = s1 + s2\n",
        "s3_op = torch.add(s1, s2)\n",
        "#Multiply\n",
        "s4 = s1 * s2\n",
        "#Subtract\n",
        "s5 = s1 - s2\n",
        "#Division\n",
        "s6 = s1 / s2\n",
        "\n",
        "print(\"`s3`: {}\".format(s3.numpy()))\n",
        "print(\"`s4`: {}\".format(s4.numpy()))\n",
        "print(\"`s5`: {}\".format(s5.numpy()))\n",
        "print(\"`s6`: {}\".format(s6.numpy()))\n",
        "print(\"`s3_op`: {}\".format(s3_op.numpy()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HIcK2V6RdeFJ",
        "outputId": "6c08ccff-a58d-4ddb-803b-eaf5b06a4b00"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "`s3`: [3.  8.8]\n",
            "`s4`: [ 2.   15.75]\n",
            "`s5`: [-1.        -3.8000002]\n",
            "`s6`: [0.5        0.39682537]\n",
            "`s3_op`: [3.  8.8]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Neural networks**\n",
        "\n",
        "\"\\n\",\n",
        "        \"![alt text](https://raw.githubusercontent.com/aamini/introtodeeplearning/master/lab1/img/computation-graph-2.png)\\n\",\n",
        "        \"\\n\""
      ],
      "metadata": {
        "id": "CjSBpoAZeRZH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the input placeholder\n",
        "X = tf.keras.Input(shape = (2,), dtype = tf.float32)\n",
        "\n",
        "# Define the weights and bias\n",
        "W = tf.Variable(tf.random.truncated_normal([2, 1], stddev=0.1), name='weight')\n",
        "b = tf.Variable(tf.zeros([1]), name='bias')\n",
        "\n",
        "# Define placeholder for true labels\n",
        "y_true = tf.keras.Input(shape=(1,), dtype=tf.float32) # Placeholder for true labels\n",
        "\n",
        "# Define the model\n",
        "def my_model(X):\n",
        "    y_pred = tf.matmul(X, W) + b\n",
        "    activation = tf.sigmoid(y_pred)\n",
        "    return activation\n",
        "\n",
        "# Define the loss function\n",
        "def my_loss(y_true, y_pred):\n",
        "    return tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels=y_true, logits=y_pred))\n",
        "\n",
        "# Define the optimizer\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.01)\n",
        "\n",
        "# Train the model\n",
        "def train_step(X_train, y_train):\n",
        "    with tf.GradientTape() as tape: # Use GradientTape to track computations\n",
        "        y_pred = my_model(X_train)\n",
        "        loss_value = my_loss(y_train, y_pred)\n",
        "    grads = tape.gradient(loss_value, [W, b]) # Calculate gradients\n",
        "    optimizer.apply_gradients(zip(grads, [W, b])) # Apply gradients\n",
        "    return loss_value\n",
        "\n",
        "\n",
        "\n",
        "# Initialize the variables\n",
        "# Create some example training data\n",
        "X_train = tf.constant([[1.0, 2.0], [3.0, 4.0]]) # Example training features\n",
        "y_train = tf.constant([[0.0], [1.0]]) # Example training labels\n",
        "# Train the model - No session required\n",
        "for i in range(1000):\n",
        "    # Assuming X_train and y_train are defined elsewhere\n",
        "    loss_value = train_step(X_train, y_train)\n",
        "    if i % 100 == 0:\n",
        "        print(\"Loss at step {}: {}\".format(i, loss_value))\n",
        "\n",
        "# Make predictions - No session required\n",
        "# Assuming X_test is defined elsewhere\n",
        "# Create some example test data\n",
        "X_test = tf.constant([[2.0, 3.0]]) # Example test features\n",
        "predictions = my_model(X_test)\n",
        "print(\"Predictions: {}\".format(predictions))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rNLjaSg3g5_W",
        "outputId": "d5cee56a-138e-49ae-df31-d2aca606119b"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss at step 0: 0.7298864126205444\n",
            "Loss at step 100: 0.6528460383415222\n",
            "Loss at step 200: 0.6007171869277954\n",
            "Loss at step 300: 0.5688238143920898\n",
            "Loss at step 400: 0.5496795177459717\n",
            "Loss at step 500: 0.5377026200294495\n",
            "Loss at step 600: 0.5298115015029907\n",
            "Loss at step 700: 0.5243597030639648\n",
            "Loss at step 800: 0.5204384326934814\n",
            "Loss at step 900: 0.5175217390060425\n",
            "Predictions: [[0.5129538]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Repeat the previous example using pytorch\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "# Define the input placeholder\n",
        "X = torch.randn(2, 2)\n",
        "\n",
        "# Define the weights and bias\n",
        "W = torch.randn(2, 1, requires_grad=True)\n",
        "b = torch.randn(1, requires_grad=True)\n",
        "\n",
        "# Define placeholder for true labels\n",
        "y_true = torch.randn(2,1)\n",
        "\n",
        "# Define the model\n",
        "def my_model(X):\n",
        "    y_pred = torch.matmul(X, W) + b\n",
        "    activation = torch.sigmoid(y_pred)\n",
        "    return activation\n",
        "\n",
        "# Define the loss function\n",
        "def my_loss(y_true, y_pred):\n",
        "    return torch.nn.functional.binary_cross_entropy(y_pred, y_true)\n",
        "\n",
        "# Define the optimizer\n",
        "optimizer = optim.Adam([W, b], lr=0.01)\n",
        "\n",
        "# Train the model\n",
        "for i in range(1000):\n",
        "    # Forward pass\n",
        "    y_pred = my_model(X)\n",
        "    loss = my_loss(y_true, y_pred)\n",
        "\n",
        "    # Backward pass\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # Print the loss every 100 iterations\n",
        "    if i % 100 == 0:\n",
        "        print(\"Loss at step {}: {}\".format(i, loss.item()))\n",
        "\n",
        "# Make predictions\n",
        "X_test = torch.randn(1, 2)\n",
        "predictions = my_model(X_test)\n",
        "print(\"Predictions: {}\".format(predictions))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7HeO3u_Dj_Sv",
        "outputId": "ae26a1d8-2a7b-4718-ef8c-27d97fbfda5d"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss at step 0: 1.0158309936523438\n",
            "Loss at step 100: 0.6820676326751709\n",
            "Loss at step 200: 0.6658444404602051\n",
            "Loss at step 300: 0.6531088352203369\n",
            "Loss at step 400: 0.645041823387146\n",
            "Loss at step 500: 0.6406632661819458\n",
            "Loss at step 600: 0.6385765075683594\n",
            "Loss at step 700: 0.6376936435699463\n",
            "Loss at step 800: 0.6373607516288757\n",
            "Loss at step 900: 0.6372488141059875\n",
            "Predictions: tensor([[0.8582]], grad_fn=<SigmoidBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a sequential model\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(units=1, activation='sigmoid', input_shape=(2,)),\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy')\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train, epochs=1000)\n",
        "\n",
        "# Make predictions\n",
        "#predictions = model.predict(X_test)\n",
        "\n",
        "# Make predictions\n",
        "# Convert PyTorch tensor to a NumPy array and then to a TensorFlow tensor\n",
        "X_test = tf.constant([[2.0, 3.0]]) # Example test features\n",
        "#X_test_tf = tf.convert_to_tensor(X_test_np, dtype=tf.float32)\n",
        "predictions = model.predict(X_test)\n",
        "\n",
        "# Print the predictions\n",
        "print(\"Predictions: {}\".format(predictions))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4mun1g3edaHw",
        "outputId": "3fc5cd69-e40b-4f94-ac4e-a13b4f799634"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "1/1 [==============================] - 0s 451ms/step - loss: 2.6324\n",
            "Epoch 2/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.6286\n",
            "Epoch 3/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 2.6248\n",
            "Epoch 4/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.6210\n",
            "Epoch 5/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.6172\n",
            "Epoch 6/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.6134\n",
            "Epoch 7/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.6096\n",
            "Epoch 8/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.6058\n",
            "Epoch 9/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.6020\n",
            "Epoch 10/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.5982\n",
            "Epoch 11/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.5944\n",
            "Epoch 12/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.5906\n",
            "Epoch 13/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.5868\n",
            "Epoch 14/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.5830\n",
            "Epoch 15/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.5793\n",
            "Epoch 16/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.5755\n",
            "Epoch 17/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.5717\n",
            "Epoch 18/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.5679\n",
            "Epoch 19/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.5641\n",
            "Epoch 20/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.5603\n",
            "Epoch 21/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.5566\n",
            "Epoch 22/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.5528\n",
            "Epoch 23/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.5490\n",
            "Epoch 24/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.5452\n",
            "Epoch 25/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.5415\n",
            "Epoch 26/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.5377\n",
            "Epoch 27/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.5339\n",
            "Epoch 28/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.5301\n",
            "Epoch 29/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.5264\n",
            "Epoch 30/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.5226\n",
            "Epoch 31/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.5188\n",
            "Epoch 32/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 2.5151\n",
            "Epoch 33/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.5113\n",
            "Epoch 34/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.5075\n",
            "Epoch 35/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.5038\n",
            "Epoch 36/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.5000\n",
            "Epoch 37/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.4963\n",
            "Epoch 38/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.4925\n",
            "Epoch 39/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.4888\n",
            "Epoch 40/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.4850\n",
            "Epoch 41/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.4812\n",
            "Epoch 42/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.4775\n",
            "Epoch 43/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.4737\n",
            "Epoch 44/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.4700\n",
            "Epoch 45/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.4662\n",
            "Epoch 46/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.4625\n",
            "Epoch 47/1000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 2.4588\n",
            "Epoch 48/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.4550\n",
            "Epoch 49/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.4513\n",
            "Epoch 50/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 2.4475\n",
            "Epoch 51/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.4438\n",
            "Epoch 52/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.4401\n",
            "Epoch 53/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.4363\n",
            "Epoch 54/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 2.4326\n",
            "Epoch 55/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.4289\n",
            "Epoch 56/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.4251\n",
            "Epoch 57/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.4214\n",
            "Epoch 58/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 2.4177\n",
            "Epoch 59/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.4139\n",
            "Epoch 60/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.4102\n",
            "Epoch 61/1000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 2.4065\n",
            "Epoch 62/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.4028\n",
            "Epoch 63/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.3990\n",
            "Epoch 64/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.3953\n",
            "Epoch 65/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.3916\n",
            "Epoch 66/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.3879\n",
            "Epoch 67/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.3842\n",
            "Epoch 68/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 2.3805\n",
            "Epoch 69/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.3768\n",
            "Epoch 70/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 2.3730\n",
            "Epoch 71/1000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 2.3693\n",
            "Epoch 72/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 2.3656\n",
            "Epoch 73/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.3619\n",
            "Epoch 74/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 2.3582\n",
            "Epoch 75/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.3545\n",
            "Epoch 76/1000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 2.3508\n",
            "Epoch 77/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.3471\n",
            "Epoch 78/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 2.3434\n",
            "Epoch 79/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.3397\n",
            "Epoch 80/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 2.3361\n",
            "Epoch 81/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.3324\n",
            "Epoch 82/1000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 2.3287\n",
            "Epoch 83/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.3250\n",
            "Epoch 84/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.3213\n",
            "Epoch 85/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 2.3176\n",
            "Epoch 86/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.3139\n",
            "Epoch 87/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 2.3103\n",
            "Epoch 88/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.3066\n",
            "Epoch 89/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 2.3029\n",
            "Epoch 90/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.2992\n",
            "Epoch 91/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.2956\n",
            "Epoch 92/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.2919\n",
            "Epoch 93/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.2882\n",
            "Epoch 94/1000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 2.2845\n",
            "Epoch 95/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.2809\n",
            "Epoch 96/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 2.2772\n",
            "Epoch 97/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.2736\n",
            "Epoch 98/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 2.2699\n",
            "Epoch 99/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 2.2662\n",
            "Epoch 100/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.2626\n",
            "Epoch 101/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.2589\n",
            "Epoch 102/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 2.2553\n",
            "Epoch 103/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 2.2516\n",
            "Epoch 104/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.2480\n",
            "Epoch 105/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.2443\n",
            "Epoch 106/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.2407\n",
            "Epoch 107/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.2370\n",
            "Epoch 108/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.2334\n",
            "Epoch 109/1000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 2.2298\n",
            "Epoch 110/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 2.2261\n",
            "Epoch 111/1000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 2.2225\n",
            "Epoch 112/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 2.2189\n",
            "Epoch 113/1000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 2.2152\n",
            "Epoch 114/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.2116\n",
            "Epoch 115/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 2.2080\n",
            "Epoch 116/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.2044\n",
            "Epoch 117/1000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 2.2007\n",
            "Epoch 118/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 2.1971\n",
            "Epoch 119/1000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 2.1935\n",
            "Epoch 120/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.1899\n",
            "Epoch 121/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 2.1863\n",
            "Epoch 122/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.1826\n",
            "Epoch 123/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 2.1790\n",
            "Epoch 124/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 2.1754\n",
            "Epoch 125/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 2.1718\n",
            "Epoch 126/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.1682\n",
            "Epoch 127/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.1646\n",
            "Epoch 128/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.1610\n",
            "Epoch 129/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.1574\n",
            "Epoch 130/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.1538\n",
            "Epoch 131/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.1502\n",
            "Epoch 132/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 2.1466\n",
            "Epoch 133/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.1430\n",
            "Epoch 134/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.1395\n",
            "Epoch 135/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.1359\n",
            "Epoch 136/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 2.1323\n",
            "Epoch 137/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.1287\n",
            "Epoch 138/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.1251\n",
            "Epoch 139/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.1216\n",
            "Epoch 140/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.1180\n",
            "Epoch 141/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.1144\n",
            "Epoch 142/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.1108\n",
            "Epoch 143/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 2.1073\n",
            "Epoch 144/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.1037\n",
            "Epoch 145/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 2.1002\n",
            "Epoch 146/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.0966\n",
            "Epoch 147/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.0930\n",
            "Epoch 148/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.0895\n",
            "Epoch 149/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.0859\n",
            "Epoch 150/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 2.0824\n",
            "Epoch 151/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.0788\n",
            "Epoch 152/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.0753\n",
            "Epoch 153/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 2.0717\n",
            "Epoch 154/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.0682\n",
            "Epoch 155/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 2.0647\n",
            "Epoch 156/1000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 2.0611\n",
            "Epoch 157/1000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 2.0576\n",
            "Epoch 158/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 2.0541\n",
            "Epoch 159/1000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 2.0505\n",
            "Epoch 160/1000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 2.0470\n",
            "Epoch 161/1000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 2.0435\n",
            "Epoch 162/1000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 2.0400\n",
            "Epoch 163/1000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 2.0364\n",
            "Epoch 164/1000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 2.0329\n",
            "Epoch 165/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 2.0294\n",
            "Epoch 166/1000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 2.0259\n",
            "Epoch 167/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 2.0224\n",
            "Epoch 168/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 2.0189\n",
            "Epoch 169/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 2.0154\n",
            "Epoch 170/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.0119\n",
            "Epoch 171/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 2.0084\n",
            "Epoch 172/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.0049\n",
            "Epoch 173/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 2.0014\n",
            "Epoch 174/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.9979\n",
            "Epoch 175/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.9944\n",
            "Epoch 176/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.9909\n",
            "Epoch 177/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.9874\n",
            "Epoch 178/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.9839\n",
            "Epoch 179/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.9805\n",
            "Epoch 180/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.9770\n",
            "Epoch 181/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.9735\n",
            "Epoch 182/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.9700\n",
            "Epoch 183/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.9666\n",
            "Epoch 184/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.9631\n",
            "Epoch 185/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.9597\n",
            "Epoch 186/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.9562\n",
            "Epoch 187/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 1.9527\n",
            "Epoch 188/1000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 1.9493\n",
            "Epoch 189/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 1.9458\n",
            "Epoch 190/1000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 1.9424\n",
            "Epoch 191/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 1.9389\n",
            "Epoch 192/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 1.9355\n",
            "Epoch 193/1000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 1.9321\n",
            "Epoch 194/1000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 1.9286\n",
            "Epoch 195/1000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 1.9252\n",
            "Epoch 196/1000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 1.9217\n",
            "Epoch 197/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.9183\n",
            "Epoch 198/1000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 1.9149\n",
            "Epoch 199/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 1.9115\n",
            "Epoch 200/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.9080\n",
            "Epoch 201/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.9046\n",
            "Epoch 202/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.9012\n",
            "Epoch 203/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.8978\n",
            "Epoch 204/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.8944\n",
            "Epoch 205/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.8910\n",
            "Epoch 206/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.8876\n",
            "Epoch 207/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.8842\n",
            "Epoch 208/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.8808\n",
            "Epoch 209/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.8774\n",
            "Epoch 210/1000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 1.8740\n",
            "Epoch 211/1000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 1.8706\n",
            "Epoch 212/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.8672\n",
            "Epoch 213/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.8639\n",
            "Epoch 214/1000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 1.8605\n",
            "Epoch 215/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 1.8571\n",
            "Epoch 216/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 1.8537\n",
            "Epoch 217/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.8504\n",
            "Epoch 218/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.8470\n",
            "Epoch 219/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.8436\n",
            "Epoch 220/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 1.8403\n",
            "Epoch 221/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 1.8369\n",
            "Epoch 222/1000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 1.8336\n",
            "Epoch 223/1000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 1.8302\n",
            "Epoch 224/1000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 1.8269\n",
            "Epoch 225/1000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 1.8235\n",
            "Epoch 226/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 1.8202\n",
            "Epoch 227/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.8168\n",
            "Epoch 228/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 1.8135\n",
            "Epoch 229/1000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 1.8102\n",
            "Epoch 230/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 1.8068\n",
            "Epoch 231/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.8035\n",
            "Epoch 232/1000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 1.8002\n",
            "Epoch 233/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 1.7969\n",
            "Epoch 234/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 1.7936\n",
            "Epoch 235/1000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 1.7903\n",
            "Epoch 236/1000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 1.7869\n",
            "Epoch 237/1000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 1.7836\n",
            "Epoch 238/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.7803\n",
            "Epoch 239/1000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 1.7770\n",
            "Epoch 240/1000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 1.7737\n",
            "Epoch 241/1000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 1.7705\n",
            "Epoch 242/1000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 1.7672\n",
            "Epoch 243/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 1.7639\n",
            "Epoch 244/1000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 1.7606\n",
            "Epoch 245/1000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 1.7573\n",
            "Epoch 246/1000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 1.7541\n",
            "Epoch 247/1000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 1.7508\n",
            "Epoch 248/1000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 1.7475\n",
            "Epoch 249/1000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 1.7443\n",
            "Epoch 250/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.7410\n",
            "Epoch 251/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.7377\n",
            "Epoch 252/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.7345\n",
            "Epoch 253/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.7312\n",
            "Epoch 254/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.7280\n",
            "Epoch 255/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.7247\n",
            "Epoch 256/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.7215\n",
            "Epoch 257/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.7183\n",
            "Epoch 258/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.7150\n",
            "Epoch 259/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.7118\n",
            "Epoch 260/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.7086\n",
            "Epoch 261/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.7054\n",
            "Epoch 262/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.7022\n",
            "Epoch 263/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.6989\n",
            "Epoch 264/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.6957\n",
            "Epoch 265/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.6925\n",
            "Epoch 266/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.6893\n",
            "Epoch 267/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.6861\n",
            "Epoch 268/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.6829\n",
            "Epoch 269/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.6797\n",
            "Epoch 270/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.6766\n",
            "Epoch 271/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.6734\n",
            "Epoch 272/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.6702\n",
            "Epoch 273/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.6670\n",
            "Epoch 274/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.6639\n",
            "Epoch 275/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.6607\n",
            "Epoch 276/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.6575\n",
            "Epoch 277/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.6544\n",
            "Epoch 278/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.6512\n",
            "Epoch 279/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.6481\n",
            "Epoch 280/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.6449\n",
            "Epoch 281/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.6418\n",
            "Epoch 282/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.6386\n",
            "Epoch 283/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.6355\n",
            "Epoch 284/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.6324\n",
            "Epoch 285/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.6292\n",
            "Epoch 286/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.6261\n",
            "Epoch 287/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.6230\n",
            "Epoch 288/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.6199\n",
            "Epoch 289/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.6168\n",
            "Epoch 290/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.6137\n",
            "Epoch 291/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.6106\n",
            "Epoch 292/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 1.6075\n",
            "Epoch 293/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.6044\n",
            "Epoch 294/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.6013\n",
            "Epoch 295/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.5982\n",
            "Epoch 296/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.5951\n",
            "Epoch 297/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.5920\n",
            "Epoch 298/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.5890\n",
            "Epoch 299/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.5859\n",
            "Epoch 300/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.5828\n",
            "Epoch 301/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 1.5798\n",
            "Epoch 302/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.5767\n",
            "Epoch 303/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.5737\n",
            "Epoch 304/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.5706\n",
            "Epoch 305/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 1.5676\n",
            "Epoch 306/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 1.5645\n",
            "Epoch 307/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.5615\n",
            "Epoch 308/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 1.5585\n",
            "Epoch 309/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.5554\n",
            "Epoch 310/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.5524\n",
            "Epoch 311/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.5494\n",
            "Epoch 312/1000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 1.5464\n",
            "Epoch 313/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.5434\n",
            "Epoch 314/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 1.5404\n",
            "Epoch 315/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 1.5374\n",
            "Epoch 316/1000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 1.5344\n",
            "Epoch 317/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 1.5314\n",
            "Epoch 318/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.5284\n",
            "Epoch 319/1000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 1.5254\n",
            "Epoch 320/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 1.5225\n",
            "Epoch 321/1000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 1.5195\n",
            "Epoch 322/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 1.5165\n",
            "Epoch 323/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 1.5136\n",
            "Epoch 324/1000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 1.5106\n",
            "Epoch 325/1000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 1.5077\n",
            "Epoch 326/1000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 1.5047\n",
            "Epoch 327/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.5018\n",
            "Epoch 328/1000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 1.4988\n",
            "Epoch 329/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.4959\n",
            "Epoch 330/1000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 1.4930\n",
            "Epoch 331/1000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 1.4900\n",
            "Epoch 332/1000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 1.4871\n",
            "Epoch 333/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.4842\n",
            "Epoch 334/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.4813\n",
            "Epoch 335/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 1.4784\n",
            "Epoch 336/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 1.4755\n",
            "Epoch 337/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.4726\n",
            "Epoch 338/1000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 1.4697\n",
            "Epoch 339/1000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 1.4668\n",
            "Epoch 340/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 1.4639\n",
            "Epoch 341/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.4611\n",
            "Epoch 342/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.4582\n",
            "Epoch 343/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 1.4553\n",
            "Epoch 344/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.4525\n",
            "Epoch 345/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.4496\n",
            "Epoch 346/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.4468\n",
            "Epoch 347/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.4439\n",
            "Epoch 348/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.4411\n",
            "Epoch 349/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.4382\n",
            "Epoch 350/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.4354\n",
            "Epoch 351/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.4326\n",
            "Epoch 352/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.4298\n",
            "Epoch 353/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.4270\n",
            "Epoch 354/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.4241\n",
            "Epoch 355/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.4213\n",
            "Epoch 356/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.4185\n",
            "Epoch 357/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.4157\n",
            "Epoch 358/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.4130\n",
            "Epoch 359/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.4102\n",
            "Epoch 360/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.4074\n",
            "Epoch 361/1000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 1.4046\n",
            "Epoch 362/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 1.4018\n",
            "Epoch 363/1000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 1.3991\n",
            "Epoch 364/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 1.3963\n",
            "Epoch 365/1000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 1.3936\n",
            "Epoch 366/1000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 1.3908\n",
            "Epoch 367/1000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 1.3881\n",
            "Epoch 368/1000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 1.3853\n",
            "Epoch 369/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.3826\n",
            "Epoch 370/1000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 1.3799\n",
            "Epoch 371/1000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 1.3772\n",
            "Epoch 372/1000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 1.3745\n",
            "Epoch 373/1000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 1.3717\n",
            "Epoch 374/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 1.3690\n",
            "Epoch 375/1000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 1.3663\n",
            "Epoch 376/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 1.3636\n",
            "Epoch 377/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 1.3610\n",
            "Epoch 378/1000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 1.3583\n",
            "Epoch 379/1000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 1.3556\n",
            "Epoch 380/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 1.3529\n",
            "Epoch 381/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 1.3503\n",
            "Epoch 382/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 1.3476\n",
            "Epoch 383/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.3449\n",
            "Epoch 384/1000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 1.3423\n",
            "Epoch 385/1000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 1.3396\n",
            "Epoch 386/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 1.3370\n",
            "Epoch 387/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 1.3344\n",
            "Epoch 388/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 1.3317\n",
            "Epoch 389/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 1.3291\n",
            "Epoch 390/1000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 1.3265\n",
            "Epoch 391/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 1.3239\n",
            "Epoch 392/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 1.3213\n",
            "Epoch 393/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.3187\n",
            "Epoch 394/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.3161\n",
            "Epoch 395/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.3135\n",
            "Epoch 396/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.3109\n",
            "Epoch 397/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.3084\n",
            "Epoch 398/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.3058\n",
            "Epoch 399/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.3032\n",
            "Epoch 400/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.3007\n",
            "Epoch 401/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.2981\n",
            "Epoch 402/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.2956\n",
            "Epoch 403/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.2930\n",
            "Epoch 404/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.2905\n",
            "Epoch 405/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.2880\n",
            "Epoch 406/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.2854\n",
            "Epoch 407/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.2829\n",
            "Epoch 408/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.2804\n",
            "Epoch 409/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.2779\n",
            "Epoch 410/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.2754\n",
            "Epoch 411/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.2729\n",
            "Epoch 412/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.2704\n",
            "Epoch 413/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.2679\n",
            "Epoch 414/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 1.2655\n",
            "Epoch 415/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.2630\n",
            "Epoch 416/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.2605\n",
            "Epoch 417/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.2581\n",
            "Epoch 418/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.2556\n",
            "Epoch 419/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.2532\n",
            "Epoch 420/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.2507\n",
            "Epoch 421/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.2483\n",
            "Epoch 422/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.2459\n",
            "Epoch 423/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.2435\n",
            "Epoch 424/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.2410\n",
            "Epoch 425/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.2386\n",
            "Epoch 426/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.2362\n",
            "Epoch 427/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.2338\n",
            "Epoch 428/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.2314\n",
            "Epoch 429/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.2290\n",
            "Epoch 430/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.2267\n",
            "Epoch 431/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.2243\n",
            "Epoch 432/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.2219\n",
            "Epoch 433/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.2196\n",
            "Epoch 434/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.2172\n",
            "Epoch 435/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.2149\n",
            "Epoch 436/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.2125\n",
            "Epoch 437/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.2102\n",
            "Epoch 438/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.2079\n",
            "Epoch 439/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.2055\n",
            "Epoch 440/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.2032\n",
            "Epoch 441/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.2009\n",
            "Epoch 442/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.1986\n",
            "Epoch 443/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.1963\n",
            "Epoch 444/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.1940\n",
            "Epoch 445/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.1917\n",
            "Epoch 446/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.1895\n",
            "Epoch 447/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.1872\n",
            "Epoch 448/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.1849\n",
            "Epoch 449/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.1827\n",
            "Epoch 450/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.1804\n",
            "Epoch 451/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.1782\n",
            "Epoch 452/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.1759\n",
            "Epoch 453/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.1737\n",
            "Epoch 454/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.1715\n",
            "Epoch 455/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.1692\n",
            "Epoch 456/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.1670\n",
            "Epoch 457/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.1648\n",
            "Epoch 458/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 1.1626\n",
            "Epoch 459/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.1604\n",
            "Epoch 460/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.1582\n",
            "Epoch 461/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.1560\n",
            "Epoch 462/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.1539\n",
            "Epoch 463/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.1517\n",
            "Epoch 464/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.1495\n",
            "Epoch 465/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.1474\n",
            "Epoch 466/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.1452\n",
            "Epoch 467/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.1431\n",
            "Epoch 468/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.1409\n",
            "Epoch 469/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.1388\n",
            "Epoch 470/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.1367\n",
            "Epoch 471/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.1346\n",
            "Epoch 472/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.1325\n",
            "Epoch 473/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.1304\n",
            "Epoch 474/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.1283\n",
            "Epoch 475/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.1262\n",
            "Epoch 476/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.1241\n",
            "Epoch 477/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 1.1220\n",
            "Epoch 478/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.1199\n",
            "Epoch 479/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 1.1179\n",
            "Epoch 480/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.1158\n",
            "Epoch 481/1000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 1.1138\n",
            "Epoch 482/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 1.1117\n",
            "Epoch 483/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 1.1097\n",
            "Epoch 484/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 1.1076\n",
            "Epoch 485/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 1.1056\n",
            "Epoch 486/1000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 1.1036\n",
            "Epoch 487/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.1016\n",
            "Epoch 488/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.0996\n",
            "Epoch 489/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.0976\n",
            "Epoch 490/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.0956\n",
            "Epoch 491/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.0936\n",
            "Epoch 492/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.0916\n",
            "Epoch 493/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.0896\n",
            "Epoch 494/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.0877\n",
            "Epoch 495/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.0857\n",
            "Epoch 496/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.0838\n",
            "Epoch 497/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.0818\n",
            "Epoch 498/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 1.0799\n",
            "Epoch 499/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.0779\n",
            "Epoch 500/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 1.0760\n",
            "Epoch 501/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.0741\n",
            "Epoch 502/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.0722\n",
            "Epoch 503/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.0703\n",
            "Epoch 504/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.0684\n",
            "Epoch 505/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 1.0665\n",
            "Epoch 506/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 1.0646\n",
            "Epoch 507/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 1.0627\n",
            "Epoch 508/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.0608\n",
            "Epoch 509/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 1.0590\n",
            "Epoch 510/1000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 1.0571\n",
            "Epoch 511/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 1.0552\n",
            "Epoch 512/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.0534\n",
            "Epoch 513/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 1.0516\n",
            "Epoch 514/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.0497\n",
            "Epoch 515/1000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 1.0479\n",
            "Epoch 516/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 1.0461\n",
            "Epoch 517/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.0443\n",
            "Epoch 518/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.0425\n",
            "Epoch 519/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.0407\n",
            "Epoch 520/1000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 1.0389\n",
            "Epoch 521/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.0371\n",
            "Epoch 522/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.0353\n",
            "Epoch 523/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.0335\n",
            "Epoch 524/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.0317\n",
            "Epoch 525/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 1.0300\n",
            "Epoch 526/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.0282\n",
            "Epoch 527/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 1.0265\n",
            "Epoch 528/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 1.0247\n",
            "Epoch 529/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 1.0230\n",
            "Epoch 530/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.0213\n",
            "Epoch 531/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.0196\n",
            "Epoch 532/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.0178\n",
            "Epoch 533/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.0161\n",
            "Epoch 534/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.0144\n",
            "Epoch 535/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.0127\n",
            "Epoch 536/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.0110\n",
            "Epoch 537/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.0094\n",
            "Epoch 538/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.0077\n",
            "Epoch 539/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.0060\n",
            "Epoch 540/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 1.0044\n",
            "Epoch 541/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.0027\n",
            "Epoch 542/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.0010\n",
            "Epoch 543/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.9994\n",
            "Epoch 544/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.9978\n",
            "Epoch 545/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.9961\n",
            "Epoch 546/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.9945\n",
            "Epoch 547/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.9929\n",
            "Epoch 548/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.9913\n",
            "Epoch 549/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.9897\n",
            "Epoch 550/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.9881\n",
            "Epoch 551/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.9865\n",
            "Epoch 552/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.9849\n",
            "Epoch 553/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.9833\n",
            "Epoch 554/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.9818\n",
            "Epoch 555/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.9802\n",
            "Epoch 556/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.9786\n",
            "Epoch 557/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.9771\n",
            "Epoch 558/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.9755\n",
            "Epoch 559/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.9740\n",
            "Epoch 560/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.9725\n",
            "Epoch 561/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.9709\n",
            "Epoch 562/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.9694\n",
            "Epoch 563/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.9679\n",
            "Epoch 564/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.9664\n",
            "Epoch 565/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.9649\n",
            "Epoch 566/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.9634\n",
            "Epoch 567/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.9619\n",
            "Epoch 568/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.9604\n",
            "Epoch 569/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.9589\n",
            "Epoch 570/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.9575\n",
            "Epoch 571/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.9560\n",
            "Epoch 572/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.9545\n",
            "Epoch 573/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.9531\n",
            "Epoch 574/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.9517\n",
            "Epoch 575/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.9502\n",
            "Epoch 576/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.9488\n",
            "Epoch 577/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.9474\n",
            "Epoch 578/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.9459\n",
            "Epoch 579/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.9445\n",
            "Epoch 580/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.9431\n",
            "Epoch 581/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.9417\n",
            "Epoch 582/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.9403\n",
            "Epoch 583/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.9389\n",
            "Epoch 584/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.9375\n",
            "Epoch 585/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.9362\n",
            "Epoch 586/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.9348\n",
            "Epoch 587/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.9334\n",
            "Epoch 588/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.9321\n",
            "Epoch 589/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.9307\n",
            "Epoch 590/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.9294\n",
            "Epoch 591/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.9280\n",
            "Epoch 592/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.9267\n",
            "Epoch 593/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.9254\n",
            "Epoch 594/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.9241\n",
            "Epoch 595/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.9227\n",
            "Epoch 596/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.9214\n",
            "Epoch 597/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.9201\n",
            "Epoch 598/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.9188\n",
            "Epoch 599/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.9175\n",
            "Epoch 600/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.9162\n",
            "Epoch 601/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.9150\n",
            "Epoch 602/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.9137\n",
            "Epoch 603/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.9124\n",
            "Epoch 604/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.9112\n",
            "Epoch 605/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.9099\n",
            "Epoch 606/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.9087\n",
            "Epoch 607/1000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.9074\n",
            "Epoch 608/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.9062\n",
            "Epoch 609/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.9049\n",
            "Epoch 610/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.9037\n",
            "Epoch 611/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.9025\n",
            "Epoch 612/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.9013\n",
            "Epoch 613/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.9001\n",
            "Epoch 614/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.8989\n",
            "Epoch 615/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.8977\n",
            "Epoch 616/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.8965\n",
            "Epoch 617/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.8953\n",
            "Epoch 618/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.8941\n",
            "Epoch 619/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.8929\n",
            "Epoch 620/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.8917\n",
            "Epoch 621/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.8906\n",
            "Epoch 622/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.8894\n",
            "Epoch 623/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.8883\n",
            "Epoch 624/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.8871\n",
            "Epoch 625/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.8860\n",
            "Epoch 626/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.8848\n",
            "Epoch 627/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.8837\n",
            "Epoch 628/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.8826\n",
            "Epoch 629/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.8815\n",
            "Epoch 630/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.8803\n",
            "Epoch 631/1000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.8792\n",
            "Epoch 632/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.8781\n",
            "Epoch 633/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.8770\n",
            "Epoch 634/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.8759\n",
            "Epoch 635/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.8749\n",
            "Epoch 636/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.8738\n",
            "Epoch 637/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.8727\n",
            "Epoch 638/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.8716\n",
            "Epoch 639/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.8706\n",
            "Epoch 640/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.8695\n",
            "Epoch 641/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.8684\n",
            "Epoch 642/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.8674\n",
            "Epoch 643/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.8663\n",
            "Epoch 644/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.8653\n",
            "Epoch 645/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.8643\n",
            "Epoch 646/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.8632\n",
            "Epoch 647/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.8622\n",
            "Epoch 648/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.8612\n",
            "Epoch 649/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.8602\n",
            "Epoch 650/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.8592\n",
            "Epoch 651/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.8582\n",
            "Epoch 652/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.8572\n",
            "Epoch 653/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.8562\n",
            "Epoch 654/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.8552\n",
            "Epoch 655/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.8542\n",
            "Epoch 656/1000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.8532\n",
            "Epoch 657/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.8522\n",
            "Epoch 658/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.8513\n",
            "Epoch 659/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.8503\n",
            "Epoch 660/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.8494\n",
            "Epoch 661/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.8484\n",
            "Epoch 662/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.8474\n",
            "Epoch 663/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.8465\n",
            "Epoch 664/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.8456\n",
            "Epoch 665/1000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.8446\n",
            "Epoch 666/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.8437\n",
            "Epoch 667/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.8428\n",
            "Epoch 668/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.8419\n",
            "Epoch 669/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.8409\n",
            "Epoch 670/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.8400\n",
            "Epoch 671/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.8391\n",
            "Epoch 672/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.8382\n",
            "Epoch 673/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.8373\n",
            "Epoch 674/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.8364\n",
            "Epoch 675/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.8355\n",
            "Epoch 676/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.8347\n",
            "Epoch 677/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.8338\n",
            "Epoch 678/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.8329\n",
            "Epoch 679/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.8320\n",
            "Epoch 680/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.8312\n",
            "Epoch 681/1000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.8303\n",
            "Epoch 682/1000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.8295\n",
            "Epoch 683/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.8286\n",
            "Epoch 684/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.8278\n",
            "Epoch 685/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.8269\n",
            "Epoch 686/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.8261\n",
            "Epoch 687/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.8252\n",
            "Epoch 688/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.8244\n",
            "Epoch 689/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.8236\n",
            "Epoch 690/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.8228\n",
            "Epoch 691/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.8220\n",
            "Epoch 692/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.8211\n",
            "Epoch 693/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.8203\n",
            "Epoch 694/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.8195\n",
            "Epoch 695/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.8187\n",
            "Epoch 696/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.8179\n",
            "Epoch 697/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.8171\n",
            "Epoch 698/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.8164\n",
            "Epoch 699/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.8156\n",
            "Epoch 700/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.8148\n",
            "Epoch 701/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.8140\n",
            "Epoch 702/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.8133\n",
            "Epoch 703/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.8125\n",
            "Epoch 704/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.8117\n",
            "Epoch 705/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.8110\n",
            "Epoch 706/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.8102\n",
            "Epoch 707/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.8095\n",
            "Epoch 708/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.8087\n",
            "Epoch 709/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.8080\n",
            "Epoch 710/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.8072\n",
            "Epoch 711/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.8065\n",
            "Epoch 712/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.8058\n",
            "Epoch 713/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.8051\n",
            "Epoch 714/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.8043\n",
            "Epoch 715/1000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.8036\n",
            "Epoch 716/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.8029\n",
            "Epoch 717/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.8022\n",
            "Epoch 718/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.8015\n",
            "Epoch 719/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.8008\n",
            "Epoch 720/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.8001\n",
            "Epoch 721/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.7994\n",
            "Epoch 722/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.7987\n",
            "Epoch 723/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.7980\n",
            "Epoch 724/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.7973\n",
            "Epoch 725/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.7966\n",
            "Epoch 726/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.7960\n",
            "Epoch 727/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.7953\n",
            "Epoch 728/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.7946\n",
            "Epoch 729/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.7940\n",
            "Epoch 730/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.7933\n",
            "Epoch 731/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.7926\n",
            "Epoch 732/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.7920\n",
            "Epoch 733/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.7913\n",
            "Epoch 734/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.7907\n",
            "Epoch 735/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.7900\n",
            "Epoch 736/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.7894\n",
            "Epoch 737/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.7888\n",
            "Epoch 738/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.7881\n",
            "Epoch 739/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.7875\n",
            "Epoch 740/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.7869\n",
            "Epoch 741/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.7862\n",
            "Epoch 742/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.7856\n",
            "Epoch 743/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.7850\n",
            "Epoch 744/1000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.7844\n",
            "Epoch 745/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.7838\n",
            "Epoch 746/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.7832\n",
            "Epoch 747/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.7826\n",
            "Epoch 748/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.7820\n",
            "Epoch 749/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.7814\n",
            "Epoch 750/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.7808\n",
            "Epoch 751/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.7802\n",
            "Epoch 752/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.7796\n",
            "Epoch 753/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.7790\n",
            "Epoch 754/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.7784\n",
            "Epoch 755/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.7778\n",
            "Epoch 756/1000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.7773\n",
            "Epoch 757/1000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.7767\n",
            "Epoch 758/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.7761\n",
            "Epoch 759/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.7756\n",
            "Epoch 760/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.7750\n",
            "Epoch 761/1000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.7744\n",
            "Epoch 762/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.7739\n",
            "Epoch 763/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.7733\n",
            "Epoch 764/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.7728\n",
            "Epoch 765/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.7722\n",
            "Epoch 766/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.7717\n",
            "Epoch 767/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.7711\n",
            "Epoch 768/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.7706\n",
            "Epoch 769/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.7701\n",
            "Epoch 770/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.7695\n",
            "Epoch 771/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.7690\n",
            "Epoch 772/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.7685\n",
            "Epoch 773/1000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.7679\n",
            "Epoch 774/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.7674\n",
            "Epoch 775/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.7669\n",
            "Epoch 776/1000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.7664\n",
            "Epoch 777/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.7659\n",
            "Epoch 778/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.7654\n",
            "Epoch 779/1000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.7648\n",
            "Epoch 780/1000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.7643\n",
            "Epoch 781/1000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.7638\n",
            "Epoch 782/1000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.7633\n",
            "Epoch 783/1000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.7628\n",
            "Epoch 784/1000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.7623\n",
            "Epoch 785/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.7619\n",
            "Epoch 786/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.7614\n",
            "Epoch 787/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.7609\n",
            "Epoch 788/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.7604\n",
            "Epoch 789/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.7599\n",
            "Epoch 790/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.7594\n",
            "Epoch 791/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.7589\n",
            "Epoch 792/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7585\n",
            "Epoch 793/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7580\n",
            "Epoch 794/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.7575\n",
            "Epoch 795/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.7571\n",
            "Epoch 796/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.7566\n",
            "Epoch 797/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.7561\n",
            "Epoch 798/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.7557\n",
            "Epoch 799/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7552\n",
            "Epoch 800/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.7548\n",
            "Epoch 801/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.7543\n",
            "Epoch 802/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.7539\n",
            "Epoch 803/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.7534\n",
            "Epoch 804/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7530\n",
            "Epoch 805/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.7525\n",
            "Epoch 806/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7521\n",
            "Epoch 807/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.7516\n",
            "Epoch 808/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.7512\n",
            "Epoch 809/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.7508\n",
            "Epoch 810/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.7503\n",
            "Epoch 811/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.7499\n",
            "Epoch 812/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.7495\n",
            "Epoch 813/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7490\n",
            "Epoch 814/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.7486\n",
            "Epoch 815/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.7482\n",
            "Epoch 816/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.7478\n",
            "Epoch 817/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.7474\n",
            "Epoch 818/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.7469\n",
            "Epoch 819/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7465\n",
            "Epoch 820/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7461\n",
            "Epoch 821/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.7457\n",
            "Epoch 822/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7453\n",
            "Epoch 823/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.7449\n",
            "Epoch 824/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.7445\n",
            "Epoch 825/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7441\n",
            "Epoch 826/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.7437\n",
            "Epoch 827/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.7433\n",
            "Epoch 828/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7429\n",
            "Epoch 829/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.7425\n",
            "Epoch 830/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7421\n",
            "Epoch 831/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.7417\n",
            "Epoch 832/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.7413\n",
            "Epoch 833/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.7410\n",
            "Epoch 834/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.7406\n",
            "Epoch 835/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.7402\n",
            "Epoch 836/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7398\n",
            "Epoch 837/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7394\n",
            "Epoch 838/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.7391\n",
            "Epoch 839/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.7387\n",
            "Epoch 840/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.7383\n",
            "Epoch 841/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.7379\n",
            "Epoch 842/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.7376\n",
            "Epoch 843/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.7372\n",
            "Epoch 844/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.7368\n",
            "Epoch 845/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.7365\n",
            "Epoch 846/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.7361\n",
            "Epoch 847/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.7358\n",
            "Epoch 848/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7354\n",
            "Epoch 849/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.7351\n",
            "Epoch 850/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.7347\n",
            "Epoch 851/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.7343\n",
            "Epoch 852/1000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.7340\n",
            "Epoch 853/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.7336\n",
            "Epoch 854/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7333\n",
            "Epoch 855/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7330\n",
            "Epoch 856/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.7326\n",
            "Epoch 857/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.7323\n",
            "Epoch 858/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.7319\n",
            "Epoch 859/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7316\n",
            "Epoch 860/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.7312\n",
            "Epoch 861/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.7309\n",
            "Epoch 862/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.7306\n",
            "Epoch 863/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.7302\n",
            "Epoch 864/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.7299\n",
            "Epoch 865/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.7296\n",
            "Epoch 866/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7293\n",
            "Epoch 867/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.7289\n",
            "Epoch 868/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7286\n",
            "Epoch 869/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.7283\n",
            "Epoch 870/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.7280\n",
            "Epoch 871/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.7276\n",
            "Epoch 872/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.7273\n",
            "Epoch 873/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.7270\n",
            "Epoch 874/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.7267\n",
            "Epoch 875/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.7264\n",
            "Epoch 876/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.7260\n",
            "Epoch 877/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.7257\n",
            "Epoch 878/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.7254\n",
            "Epoch 879/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7251\n",
            "Epoch 880/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.7248\n",
            "Epoch 881/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.7245\n",
            "Epoch 882/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7242\n",
            "Epoch 883/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.7239\n",
            "Epoch 884/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.7236\n",
            "Epoch 885/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.7233\n",
            "Epoch 886/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.7230\n",
            "Epoch 887/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.7227\n",
            "Epoch 888/1000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.7224\n",
            "Epoch 889/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.7221\n",
            "Epoch 890/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.7218\n",
            "Epoch 891/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.7215\n",
            "Epoch 892/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.7212\n",
            "Epoch 893/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.7209\n",
            "Epoch 894/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.7206\n",
            "Epoch 895/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.7203\n",
            "Epoch 896/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.7201\n",
            "Epoch 897/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.7198\n",
            "Epoch 898/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.7195\n",
            "Epoch 899/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.7192\n",
            "Epoch 900/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.7189\n",
            "Epoch 901/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.7186\n",
            "Epoch 902/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.7184\n",
            "Epoch 903/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.7181\n",
            "Epoch 904/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7178\n",
            "Epoch 905/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.7175\n",
            "Epoch 906/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.7172\n",
            "Epoch 907/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.7170\n",
            "Epoch 908/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.7167\n",
            "Epoch 909/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.7164\n",
            "Epoch 910/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.7162\n",
            "Epoch 911/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.7159\n",
            "Epoch 912/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.7156\n",
            "Epoch 913/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.7153\n",
            "Epoch 914/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.7151\n",
            "Epoch 915/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.7148\n",
            "Epoch 916/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.7145\n",
            "Epoch 917/1000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.7143\n",
            "Epoch 918/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.7140\n",
            "Epoch 919/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.7138\n",
            "Epoch 920/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.7135\n",
            "Epoch 921/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.7132\n",
            "Epoch 922/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.7130\n",
            "Epoch 923/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.7127\n",
            "Epoch 924/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.7125\n",
            "Epoch 925/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.7122\n",
            "Epoch 926/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.7120\n",
            "Epoch 927/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.7117\n",
            "Epoch 928/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.7114\n",
            "Epoch 929/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.7112\n",
            "Epoch 930/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.7109\n",
            "Epoch 931/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.7107\n",
            "Epoch 932/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.7104\n",
            "Epoch 933/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.7102\n",
            "Epoch 934/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.7099\n",
            "Epoch 935/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.7097\n",
            "Epoch 936/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.7095\n",
            "Epoch 937/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.7092\n",
            "Epoch 938/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.7090\n",
            "Epoch 939/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.7087\n",
            "Epoch 940/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.7085\n",
            "Epoch 941/1000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.7082\n",
            "Epoch 942/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.7080\n",
            "Epoch 943/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.7078\n",
            "Epoch 944/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.7075\n",
            "Epoch 945/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.7073\n",
            "Epoch 946/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.7071\n",
            "Epoch 947/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.7068\n",
            "Epoch 948/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.7066\n",
            "Epoch 949/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.7063\n",
            "Epoch 950/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.7061\n",
            "Epoch 951/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.7059\n",
            "Epoch 952/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.7056\n",
            "Epoch 953/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.7054\n",
            "Epoch 954/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7052\n",
            "Epoch 955/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.7050\n",
            "Epoch 956/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.7047\n",
            "Epoch 957/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7045\n",
            "Epoch 958/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7043\n",
            "Epoch 959/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.7040\n",
            "Epoch 960/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7038\n",
            "Epoch 961/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.7036\n",
            "Epoch 962/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7034\n",
            "Epoch 963/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7032\n",
            "Epoch 964/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.7029\n",
            "Epoch 965/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.7027\n",
            "Epoch 966/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7025\n",
            "Epoch 967/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.7023\n",
            "Epoch 968/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7020\n",
            "Epoch 969/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.7018\n",
            "Epoch 970/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7016\n",
            "Epoch 971/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7014\n",
            "Epoch 972/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.7012\n",
            "Epoch 973/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7010\n",
            "Epoch 974/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7007\n",
            "Epoch 975/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7005\n",
            "Epoch 976/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.7003\n",
            "Epoch 977/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7001\n",
            "Epoch 978/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6999\n",
            "Epoch 979/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6997\n",
            "Epoch 980/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6995\n",
            "Epoch 981/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6992\n",
            "Epoch 982/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6990\n",
            "Epoch 983/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6988\n",
            "Epoch 984/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6986\n",
            "Epoch 985/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6984\n",
            "Epoch 986/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6982\n",
            "Epoch 987/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6980\n",
            "Epoch 988/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6978\n",
            "Epoch 989/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6976\n",
            "Epoch 990/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6974\n",
            "Epoch 991/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6972\n",
            "Epoch 992/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6970\n",
            "Epoch 993/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6968\n",
            "Epoch 994/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6966\n",
            "Epoch 995/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6964\n",
            "Epoch 996/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6961\n",
            "Epoch 997/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6959\n",
            "Epoch 998/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6957\n",
            "Epoch 999/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6955\n",
            "Epoch 1000/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6953\n",
            "1/1 [==============================] - 0s 155ms/step\n",
            "Predictions: [[0.5834172]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "\n",
        "X_train = torch.tensor([[1.0, 2.0], [3.0, 4.0]]) # Example training features\n",
        "y_train = torch.tensor([[0.0], [1.0]]) # Example training labels\n",
        "X_test = torch.tensor([[2.0, 3.0]])\n",
        "# Create a sequential model\n",
        "model = torch.nn.Sequential(\n",
        "    torch.nn.Linear(2, 1),\n",
        "    torch.nn.Sigmoid(),\n",
        ")\n",
        "\n",
        "# Define the optimizer and loss function\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "loss_fn = torch.nn.BCELoss()\n",
        "\n",
        "# Train the model\n",
        "for epoch in range(1000):\n",
        "    # Forward pass\n",
        "    y_pred = model(X_train)\n",
        "    loss = loss_fn(y_pred, y_train)\n",
        "\n",
        "    # Backward pass and update weights\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "# Make predictions\n",
        "\n",
        "predictions = model(X_test)\n",
        "\n",
        "# Print the predictions\n",
        "print(\"Predictions:\", predictions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "US9EkfIafVzN",
        "outputId": "4af55aa5-0c75-47df-fb75-dca677fdba41"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predictions: tensor([[0.6017]], grad_fn=<SigmoidBackward0>)\n"
          ]
        }
      ]
    }
  ]
}